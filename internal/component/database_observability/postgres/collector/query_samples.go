package collector

import (
	"context"
	"database/sql"
	"fmt"
	"math"
	"slices"
	"sort"
	"time"

	"github.com/go-kit/log"
	"github.com/lib/pq"
	"go.uber.org/atomic"

	"github.com/grafana/alloy/internal/component/common/loki"
	"github.com/grafana/alloy/internal/component/database_observability"
	"github.com/grafana/alloy/internal/runtime/logging"
	"github.com/grafana/alloy/internal/runtime/logging/level"
)

const (
	QuerySamplesCollector = "query_samples"
	OP_QUERY_SAMPLE       = "query_sample"
	OP_WAIT_EVENT         = "wait_event"
)

const (
	queryTextClause     = ", s.query"
	stateActive         = "active"
	waitEventTypeLock   = "Lock"
	stateIdleTxnAborted = "idle in transaction (aborted)"
	stateIdleTxn        = "idle in transaction"
)

const finalizationRateWindow = 5 * time.Minute

const selectPgStatActivity = `
	SELECT
		clock_timestamp() as now,
		d.datname,
		s.pid,
		s.leader_pid,
		s.usename,
		s.application_name,
		s.client_addr,
		s.client_port,
		s.backend_type,
		s.backend_start,
		s.backend_xid,
		s.backend_xmin,
		s.xact_start,
		s.state,
		s.state_change,
		s.wait_event_type,
		s.wait_event,
		s.query_start,
		s.query_id
		%s
	FROM pg_stat_activity s
		JOIN pg_database d ON s.datid = d.oid AND NOT d.datistemplate AND d.datallowconn
	WHERE
		s.pid != pg_backend_pid() AND
		s.state != 'idle' AND
		(
			s.backend_type != 'client backend' OR
			(
				coalesce(TRIM(s.query), '') != '' AND
				s.query_id != 0
			)
		)
`

const selectBlockingPIDs = `
    SELECT pid, pg_blocking_pids(pid) 
    FROM pg_stat_activity 
    WHERE wait_event_type = 'Lock' AND pid != pg_backend_pid()
`

type QuerySamplesInfo struct {
	DatabaseName    sql.NullString
	DatabaseID      int
	PID             int
	LeaderPID       sql.NullInt64
	UserSysID       int
	Username        sql.NullString
	ApplicationName sql.NullString
	ClientAddr      sql.NullString
	ClientPort      sql.NullInt32
	StateChange     sql.NullTime
	Now             time.Time
	BackendStart    sql.NullTime
	XactStart       sql.NullTime
	QueryStart      sql.NullTime
	WaitEventType   sql.NullString
	WaitEvent       sql.NullString
	State           sql.NullString
	BackendType     sql.NullString
	BackendXID      sql.NullInt32
	BackendXmin     sql.NullInt32
	QueryID         sql.NullInt64
	Query           sql.NullString
	BlockedByPIDs   pq.Int64Array
}

type QuerySamplesArguments struct {
	DB                    *sql.DB
	CollectInterval       time.Duration
	EntryHandler          loki.EntryHandler
	Logger                log.Logger
	DisableQueryRedaction bool
	BaseThrottleInterval  time.Duration
}

type QuerySamples struct {
	dbConnection          *sql.DB
	collectInterval       time.Duration
	entryHandler          loki.EntryHandler
	disableQueryRedaction bool

	logger  log.Logger
	running *atomic.Bool
	ctx     context.Context
	cancel  context.CancelFunc

	// in-memory state of running samples
	samples                      map[SampleKey]*SampleState
	baseThrottleInterval         time.Duration
	lastEmittedByQueryID         map[int64]time.Time
	recentFinalizationsByQueryID map[int64][]time.Time
	adaptiveBurstInterval        time.Duration
	burstWindowUntil             time.Time
}

// SampleKey uses (PID, QueryID, QueryStartNs) so concurrent executions of the same
// query across backends/transactions are uniquely tracked between scrapes.
type SampleKey struct {
	PID          int
	QueryID      int64
	QueryStartNs int64
}

func newSampleKey(pid int, queryID int64, queryStart sql.NullTime) SampleKey {
	key := SampleKey{PID: pid, QueryID: queryID, QueryStartNs: 0}
	if queryStart.Valid {
		key.QueryStartNs = queryStart.Time.UnixNano()
	}
	return key
}

// SampleState buffers state across scrapes and is emitted once the query
// turns idle or disappears, avoiding partial/duplicate emissions.
type SampleState struct {
	LastRow     QuerySamplesInfo
	LastSeenAt  time.Time
	LastCpuTime string // last cpu_time observed under CPU condition
	tracker     WaitEventTracker
}

// WaitEventTracker coalesces consecutive identical wait events
// to reduce log volume while preserving timing.
type WaitEventTracker struct {
	waitEvents []WaitEventOccurrence
	openIdx    int // -1 means none open
}

func newWaitEventTracker() WaitEventTracker {
	return WaitEventTracker{waitEvents: []WaitEventOccurrence{}, openIdx: -1}
}

func (t *WaitEventTracker) CloseOpen()                        { t.openIdx = -1 }
func (t *WaitEventTracker) WaitEvents() []WaitEventOccurrence { return t.waitEvents }

// WaitEventOccurrence tracks a continuous occurrence of the same wait event
// with the same blocked_by_pids set.
type WaitEventOccurrence struct {
	WaitEventType string
	WaitEvent     string
	BlockedByPIDs []int64 // normalized set (sorted, unique)
	LastWaitTime  string  // last stateDuration seen for this wait event
	LastState     string
	LastTimestamp time.Time
}

// WaitEventIdentity defines the identity of a wait-event occurrence (type, event, blocked_by set)
type WaitEventIdentity struct {
	eventType string
	event     string
	blockedBy []int64 // normalized
}

func (w WaitEventIdentity) Equal(other WaitEventIdentity) bool {
	if w.eventType != other.eventType || w.event != other.event {
		return false
	}
	return equalPIDSets(w.blockedBy, other.blockedBy)
}

func NewQuerySamples(args QuerySamplesArguments) (*QuerySamples, error) {
	return &QuerySamples{
		dbConnection:                 args.DB,
		collectInterval:              args.CollectInterval,
		entryHandler:                 args.EntryHandler,
		disableQueryRedaction:        args.DisableQueryRedaction,
		logger:                       log.With(args.Logger, "collector", QuerySamplesCollector),
		running:                      &atomic.Bool{},
		samples:                      map[SampleKey]*SampleState{},
		baseThrottleInterval:         args.BaseThrottleInterval,
		lastEmittedByQueryID:         map[int64]time.Time{},
		recentFinalizationsByQueryID: map[int64][]time.Time{},
	}, nil
}

func (c *QuerySamples) Name() string {
	return QuerySamplesCollector
}

func (c *QuerySamples) Start(ctx context.Context) error {
	if c.disableQueryRedaction {
		level.Warn(c.logger).Log("msg", "collector started with query redaction disabled. SQL text in query samples may include query parameters.")
	} else {
		level.Debug(c.logger).Log("msg", "collector started")
	}

	if c.baseThrottleInterval < 30*time.Second {
		level.Warn(c.logger).Log("msg", fmt.Sprintf("collector configured with base throttle interval below 30 seconds: %s. This may result in excessive samples volume.", c.baseThrottleInterval))
	}
	level.Debug(c.logger).Log("msg", fmt.Sprintf("collector started with base throttle interval: %s", c.baseThrottleInterval))

	c.running.Store(true)
	ctx, cancel := context.WithCancel(ctx)
	c.ctx = ctx
	c.cancel = cancel

	go func() {
		defer func() {
			c.Stop()
			c.running.Store(false)
		}()

		for {
			loopStart := time.Now()
			hasActive, err := c.fetchQuerySample(c.ctx)
			if err != nil {
				level.Error(c.logger).Log("msg", "collector error", "err", err)
			}

			elapsed := time.Since(loopStart)
			interval := c.collectInterval
			now := time.Now()
			if hasActive {
				s, window := computeBurstWindow(c.collectInterval, elapsed)
				if now.Before(c.burstWindowUntil) && c.adaptiveBurstInterval > 0 {
					// continue the current burst
					interval = c.adaptiveBurstInterval
					level.Debug(c.logger).Log("msg", "continuing the current burst window", "burst interval", c.adaptiveBurstInterval, "until", c.burstWindowUntil)
				} else if window > s {
					// start a new burst window
					c.adaptiveBurstInterval = s
					c.burstWindowUntil = now.Add(window)
					level.Debug(c.logger).Log("msg", "starting a collection burst window while there are rows in active state", "burst interval", c.adaptiveBurstInterval, "until", c.burstWindowUntil)
					interval = s
				} else {
					// don't start a new burst, use the observed latency as interval to avoid impacting database performance
					c.adaptiveBurstInterval = 0
					c.burstWindowUntil = time.Time{}
					interval = s
					level.Debug(c.logger).Log("msg", "using the observed latency as interval to avoid impacting database performance", "interval", s)
				}
			}

			select {
			case <-c.ctx.Done():
				return
			case <-time.After(interval):
				// continue loop
			}
		}
	}()

	return nil
}

func (c *QuerySamples) Stopped() bool {
	return !c.running.Load()
}

// Stop should be kept idempotent
func (c *QuerySamples) Stop() {
	c.cancel()
}

func (c *QuerySamples) fetchQuerySample(ctx context.Context) (hasActive bool, err error) {
	queryTextField := ""
	if c.disableQueryRedaction {
		queryTextField = queryTextClause
	}

	query := fmt.Sprintf(selectPgStatActivity, queryTextField)
	rows, err := c.dbConnection.QueryContext(ctx, query)
	if err != nil {
		return false, fmt.Errorf("failed to query pg_stat_activity: %w", err)
	}

	defer rows.Close()

	var buffered []QuerySamplesInfo
	hasLockWait := false

	for rows.Next() {
		sample, scanErr := c.scanRow(rows)
		if scanErr != nil {
			level.Error(c.logger).Log("msg", "failed to scan pg_stat_activity", "err", scanErr)
			continue
		}
		if sample.WaitEventType.Valid && sample.WaitEventType.String == waitEventTypeLock {
			hasLockWait = true
		}
		buffered = append(buffered, sample)
	}

	if err := rows.Err(); err != nil {
		return false, fmt.Errorf("failed to iterate pg_stat_activity rows: %w", err)
	}

	// Enrich blocked_by_pids only when there are lock waits
	blockedByPID := map[int]pq.Int64Array{}
	if hasLockWait {
		blockedRows, err := c.dbConnection.QueryContext(ctx, selectBlockingPIDs)
		if err != nil {
			level.Error(c.logger).Log("msg", "failed to query blocking pids", "err", err)
		} else {
			defer blockedRows.Close()
			for blockedRows.Next() {
				var pid int
				var blocked pq.Int64Array
				if err := blockedRows.Scan(&pid, &blocked); err != nil {
					level.Error(c.logger).Log("msg", "failed to scan blocking pids row", "err", err)
					continue
				}
				blockedByPID[pid] = blocked
			}
			if err := blockedRows.Err(); err != nil {
				level.Error(c.logger).Log("msg", "failed to iterate blocking pids rows", "err", err)
			}
		}
	}

	activeKeys := map[SampleKey]struct{}{}

	for _, sample := range buffered {
		if sample.WaitEventType.Valid && sample.WaitEventType.String == waitEventTypeLock {
			if blocked, ok := blockedByPID[sample.PID]; ok {
				sample.BlockedByPIDs = blocked
			}
		}
		key, procErr := c.processRow(sample)
		if procErr != nil {
			level.Debug(c.logger).Log("msg", "invalid pg_stat_activity set", "queryid", sample.QueryID.Int64, "err", procErr)
			continue
		}
		c.upsertActiveSample(key, sample)
		activeKeys[key] = struct{}{}
	}

	// finalize samples that are no longer active
	for key := range c.samples {
		if _, stillActive := activeKeys[key]; stillActive {
			continue
		}
		c.emitAndDeleteSample(key)
	}
	return len(activeKeys) > 0, nil
}

func (c *QuerySamples) scanRow(rows *sql.Rows) (QuerySamplesInfo, error) {
	sample := QuerySamplesInfo{}
	scanArgs := []interface{}{
		&sample.Now,
		&sample.DatabaseName,
		&sample.PID,
		&sample.LeaderPID,
		&sample.Username,
		&sample.ApplicationName,
		&sample.ClientAddr,
		&sample.ClientPort,
		&sample.BackendType,
		&sample.BackendStart,
		&sample.BackendXID,
		&sample.BackendXmin,
		&sample.XactStart,
		&sample.State,
		&sample.StateChange,
		&sample.WaitEventType,
		&sample.WaitEvent,
		&sample.QueryStart,
		&sample.QueryID,
	}
	if c.disableQueryRedaction {
		scanArgs = append(scanArgs, &sample.Query)
	}
	err := rows.Scan(scanArgs...)
	return sample, err
}

func (c *QuerySamples) processRow(sample QuerySamplesInfo) (SampleKey, error) {
	if err := c.validateQuerySample(sample); err != nil {
		return SampleKey{}, err
	}
	key := newSampleKey(sample.PID, sample.QueryID.Int64, sample.QueryStart)
	return key, nil
}

func (c QuerySamples) validateQuerySample(sample QuerySamplesInfo) error {
	if c.disableQueryRedaction {
		if sample.Query.Valid && sample.Query.String == "<insufficient privilege>" {
			return fmt.Errorf("insufficient privilege to access query sample set: %+v", sample)
		}
	}

	if !sample.DatabaseName.Valid {
		return fmt.Errorf("database name is not valid. sample set: %+v", sample)
	}

	return nil
}

func (c *QuerySamples) upsertActiveSample(key SampleKey, sample QuerySamplesInfo) {
	state, ok := c.samples[key]
	if !ok {
		state = &SampleState{tracker: newWaitEventTracker()}
		c.samples[key] = state
	}
	state.LastRow = sample
	state.LastSeenAt = sample.Now
	state.updateCpuTimeIfActive(sample)
	state.tracker.upsertWaitEvent(sample, sample.Now)
}

func (t *WaitEventTracker) upsertWaitEvent(sample QuerySamplesInfo, now time.Time) {
	if sample.WaitEventType.Valid && sample.WaitEvent.Valid {
		current := WaitEventIdentity{
			eventType: sample.WaitEventType.String,
			event:     sample.WaitEvent.String,
			blockedBy: normalizePIDs(sample.BlockedByPIDs),
		}
		if t.openIdx >= 0 {
			we := t.waitEvents[t.openIdx]
			existing := WaitEventIdentity{eventType: we.WaitEventType, event: we.WaitEvent, blockedBy: we.BlockedByPIDs}
			if existing.Equal(current) {
				we.LastWaitTime = calculateDuration(sample.StateChange, now)
				we.LastState = sample.State.String
				we.LastTimestamp = now
				t.waitEvents[t.openIdx] = we
				return
			}
			t.openIdx = -1
		}

		newOcc := WaitEventOccurrence{
			WaitEventType: current.eventType,
			WaitEvent:     current.event,
			BlockedByPIDs: current.blockedBy,
			LastWaitTime:  calculateDuration(sample.StateChange, now),
			LastState:     sample.State.String,
			LastTimestamp: now,
		}
		t.waitEvents = append(t.waitEvents, newOcc)
		t.openIdx = len(t.waitEvents) - 1
		return
	}

	if t.openIdx >= 0 {
		t.openIdx = -1
	}
}

func (c *QuerySamples) emitAndDeleteSample(key SampleKey) {
	state, ok := c.samples[key]
	if !ok {
		return
	}
	sampleLabels := c.buildQuerySampleLabels(state)

	now := time.Now()
	qid := state.LastRow.QueryID.Int64

	isExempt := isThrottleExempt(state)

	var perMinuteRate float64
	if !isExempt {
		window := c.recentFinalizationsByQueryID[qid]
		cutoff := now.Add(-finalizationRateWindow)
		cutoffIndex := sort.Search(len(window), func(j int) bool { return window[j].After(cutoff) })
		window = append(window[cutoffIndex:], now)
		c.recentFinalizationsByQueryID[qid] = window
		perMinuteRate = float64(len(window)) * float64(time.Minute) / float64(finalizationRateWindow)
	}

	shouldEmit := true
	if !isExempt && c.baseThrottleInterval > 0 {
		adaptiveThrottleInterval := computeAdaptiveThrottleInterval(c.baseThrottleInterval, perMinuteRate)
		if last, ok := c.lastEmittedByQueryID[qid]; ok {
			if now.Sub(last) < adaptiveThrottleInterval {
				shouldEmit = false
			}
		}
	}
	if shouldEmit {
		if !isExempt {
			c.lastEmittedByQueryID[qid] = now
		}
		c.entryHandler.Chan() <- database_observability.BuildLokiEntryWithTimestamp(
			logging.LevelInfo,
			OP_QUERY_SAMPLE,
			sampleLabels,
			state.LastSeenAt.UnixNano(),
		)
	}

	for _, we := range state.tracker.WaitEvents() {
		if we.WaitEventType == "" || we.WaitEvent == "" {
			continue
		}
		waitEventLabels := c.buildWaitEventLabels(state, we)
		c.entryHandler.Chan() <- database_observability.BuildLokiEntryWithTimestamp(
			logging.LevelInfo,
			OP_WAIT_EVENT,
			waitEventLabels,
			we.LastTimestamp.UnixNano(),
		)
	}

	delete(c.samples, key)
}

func (s *SampleState) updateCpuTimeIfActive(sample QuerySamplesInfo) {
	if !sample.WaitEventType.Valid && !sample.WaitEvent.Valid && sample.State.String == stateActive {
		s.LastCpuTime = calculateDuration(sample.StateChange, sample.Now)
	}
}

func (c *QuerySamples) buildQuerySampleLabels(state *SampleState) string {
	leaderPID := ""
	if state.LastRow.LeaderPID.Valid {
		leaderPID = fmt.Sprintf(`%d`, state.LastRow.LeaderPID.Int64)
	}
	xactDuration := calculateDuration(state.LastRow.XactStart, state.LastRow.Now)
	queryDuration := calculateDuration(state.LastRow.QueryStart, state.LastRow.Now)

	clientAddr := ""
	if state.LastRow.ClientAddr.Valid {
		clientAddr = state.LastRow.ClientAddr.String
		if state.LastRow.ClientPort.Valid {
			clientAddr = fmt.Sprintf("%s:%d", clientAddr, state.LastRow.ClientPort.Int32)
		}
	}

	labels := fmt.Sprintf(
		`datname="%s" pid="%d" leader_pid="%s" user="%s" app="%s" client="%s" backend_type="%s" state="%s" xid="%d" xmin="%d" xact_time="%s" query_time="%s" queryid="%d"`,
		state.LastRow.DatabaseName.String,
		state.LastRow.PID,
		leaderPID,
		state.LastRow.Username.String,
		state.LastRow.ApplicationName.String,
		clientAddr,
		state.LastRow.BackendType.String,
		state.LastRow.State.String,
		state.LastRow.BackendXID.Int32,
		state.LastRow.BackendXmin.Int32,
		xactDuration,
		queryDuration,
		state.LastRow.QueryID.Int64,
	)
	if state.LastCpuTime != "" {
		labels = fmt.Sprintf(`%s cpu_time="%s"`, labels, state.LastCpuTime)
	}
	if c.disableQueryRedaction && state.LastRow.Query.Valid {
		labels = fmt.Sprintf(`%s query="%s"`, labels, state.LastRow.Query.String)
	}
	return labels
}

func (c *QuerySamples) buildWaitEventLabels(state *SampleState, we WaitEventOccurrence) string {
	waitEventFullName := fmt.Sprintf("%s:%s", we.WaitEventType, we.WaitEvent)
	leaderPID := ""
	if state.LastRow.LeaderPID.Valid {
		leaderPID = fmt.Sprintf(`%d`, state.LastRow.LeaderPID.Int64)
	}
	return fmt.Sprintf(
		`datname="%s" pid="%d" leader_pid="%s" user="%s" backend_type="%s" state="%s" xid="%d" xmin="%d" wait_time="%s" wait_event_type="%s" wait_event="%s" wait_event_name="%s" blocked_by_pids="%v" queryid="%d"`,
		state.LastRow.DatabaseName.String,
		state.LastRow.PID,
		leaderPID,
		state.LastRow.Username.String,
		state.LastRow.BackendType.String,
		we.LastState,
		state.LastRow.BackendXID.Int32,
		state.LastRow.BackendXmin.Int32,
		we.LastWaitTime,
		we.WaitEventType,
		we.WaitEvent,
		waitEventFullName,
		we.BlockedByPIDs,
		state.LastRow.QueryID.Int64,
	)
}

func calculateDuration(nullableTime sql.NullTime, currentTime time.Time) string {
	if !nullableTime.Valid {
		return ""
	}
	return currentTime.Sub(nullableTime.Time).Round(time.Nanosecond).String()
}

func normalizePIDs(pids pq.Int64Array) []int64 {
	seen := make(map[int64]struct{}, len(pids))
	out := make([]int64, 0, len(pids))
	for _, pid := range pids {
		if _, ok := seen[pid]; ok {
			continue
		}
		seen[pid] = struct{}{}
		out = append(out, pid)
	}
	slices.Sort(out)
	return out
}

func equalPIDSets(a, b []int64) bool {
	if len(a) != len(b) {
		return false
	}
	for i := range a {
		if a[i] != b[i] {
			return false
		}
	}
	return true
}

func min(a, b time.Duration) time.Duration {
	if a < b {
		return a
	}
	return b
}

func isThrottleExempt(sample *SampleState) bool {
	if sample.LastRow.State.String == stateIdleTxn || sample.LastRow.State.String == stateIdleTxnAborted || len(sample.tracker.WaitEvents()) > 0 || sample.LastCpuTime != "" {
		return true
	}
	return false
}

// computeBurstWindow returns the burst interval s and the window duration W
// for time-boxed burst polling, given the collection interval and the last
// observed latency. W is bounded by 20*s to limit the number of burst polls.
//
// Rules:
//   - s_base = clamp(CI/30, 50ms..300ms)
//   - s = max(s_base, observedLatency)
//   - W = min(CI/2 - 100ms)
//   - N ≤ 20 ⇒ for a burst interval s, the window ≤ 20*s
func computeBurstWindow(collectInterval, observedLatency time.Duration) (time.Duration, time.Duration) {
	s := time.Duration(float64(collectInterval) / 30.0)
	if s < 50*time.Millisecond {
		s = 50 * time.Millisecond
	} else if s > 300*time.Millisecond {
		s = 300 * time.Millisecond
	}
	if observedLatency > s {
		s = observedLatency
	}
	guard := 100 * time.Millisecond
	capWindow := collectInterval/2 - guard
	if capWindow < 0 {
		capWindow = 0
	}

	capWindow = min(capWindow, 20*s)
	return s, capWindow
}

// computeAdaptiveThrottleInterval scales the base interval using a logarithmic factor derived
// from the per-minute finalization rate. This provides gentle backoff at high rates,
// avoiding excessive sampling:
//
//	factor = 1 + ceil(log10(max(1, per-minute-rate)))
//	effective = baseThrottleInterval * factor
//
// If baseThrottleInterval is 0, adaptive throttling is disabled and 0 is returned.
func computeAdaptiveThrottleInterval(baseThrottleInterval time.Duration, perMinuteRate float64) time.Duration {
	if baseThrottleInterval <= 0 {
		return 0
	}
	if perMinuteRate <= 1 {
		return baseThrottleInterval
	}
	r := perMinuteRate
	f := 1 + int(math.Ceil(math.Log10(r)))
	if f < 1 {
		f = 1
	} else if f > 10 {
		f = 10
	}
	return time.Duration(f) * baseThrottleInterval
}
